services:

  simulator:
    build:
      context: .
      dockerfile: log_simulator/Dockerfile
    container_name: simulator
    cpus: "1.0"
    mem_limit: "256m"
    mem_reservation: "128m"
    oom_score_adj: 500
    # restart: unless-stopped
    ports: 
      - "8000:8000"
    environment:
      # --- Simulator load (전체 부하 프로필) ---
      - SIMULATOR_SHARE=1.0
      - SIM_EVENT_MODE=domain
      - LOG_BATCH_SIZE=2000
      - TARGET_INTERVAL_SEC=0.50
      - LOOPS_PER_SERVICE=1
      # --- Simulator queue (백프레셔/스로틀) ---
      - QUEUE_SIZE=4000
      - SIM_QUEUE_WARN_RATIO=0.8
      - QUEUE_LOW_WATERMARK_RATIO=0.2
      - QUEUE_LOW_SLEEP_SCALE=1.0
      - QUEUE_THROTTLE_RATIO=0.9
      - QUEUE_THROTTLE_SLEEP=0.05
      - QUEUE_RESUME_RATIO=0.75
      - QUEUE_SOFT_THROTTLE_RATIO=0.85
      - QUEUE_SOFT_RESUME_RATIO=0.7
      - QUEUE_SOFT_SCALE_STEP=0.1
      - QUEUE_SOFT_SCALE_MIN=0.2
      - QUEUE_SOFT_SCALE_MAX=1.0
      - SIM_BEHIND_LOG_EVERY_SEC=5.0
      - SIM_DRAIN_TIMEOUT_SEC=5.0
      # --- Publisher worker ---
      - PUBLISHER_WORKERS=3
      - WORKER_BATCH_SIZE=600
      - PUBLISH_QUEUE_WARN_RATIO=0.7
      - IDLE_WARN_SEC=5
      - SEND_WARN_SEC=5
      - PUBLISH_RETRY_BACKOFF_SEC=0.2
      # --- Kafka producer ---
      - KAFKA_BOOTSTRAP=kafka:9092
      - KAFKA_CLIENT_ID=log-monitoring-simulator
      - PRODUCER_ENABLE_IDEMPOTENCE=false
      - PRODUCER_ACKS=0
      - PRODUCER_COMPRESSION=none
      - PRODUCER_LINGER_MS=20
      - PRODUCER_BATCH_NUM_MESSAGES=5000
      - PRODUCER_QUEUE_MAX_MESSAGES=200000
      - PRODUCER_QUEUE_MAX_KBYTES=65536
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./common:/app/common:ro
      - ./log_simulator:/app/log_simulator:ro
    networks: [logetlm-net]
    command: ["uvicorn", "log_simulator.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    # cpus: "0.6"
    # restart: unless-stopped
    mem_limit: "2g"
    mem_reservation: "1500m"
    oom_score_adj: 100
    ports: 
      - "29092:29092"
    environment:
      # --- KRaft 기본 ---
      CLUSTER_ID: "nkfq3mlSTrG7l5xDu8Ks9w"
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      # --- Listener / Quorum ---
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      # --- Replication / ISR (단일 브로커 기본) ---
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # --- Partitions ---
      KAFKA_NUM_PARTITIONS: 1
      # --- Storage / Heap ---
      KAFKA_LOG_DIRS: "/var/lib/kafka/logs"
      KAFKA_METADATA_LOG_DIR: "/var/lib/kafka/metadata"
      KAFKA_HEAP_OPTS: "-Xms1g -Xmx1536m"
      # --- Retention / Segment ---
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 600000
      KAFKA_LOG_RETENTION_HOURS: 2
      KAFKA_LOG_RETENTION_BYTES: 21474836480
      KAFKA_LOG_SEGMENT_BYTES: 536870912
    volumes:
      - /data/log-etlm/kafka-logs:/var/lib/kafka/logs
      - /data/log-etlm/kafka-meta:/var/lib/kafka/metadata
    ulimits:
      nofile: { soft: 100000, hard: 100000 }
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }
    healthcheck:
      # 고부하/디스크 IO 상황에서 kafka-* CLI가 오래 걸리거나 hang 될 수 있어
      # 포트 오픈 여부로 가볍게 체크한다.
      test: ["CMD-SHELL", "timeout 5s bash -lc 'echo > /dev/tcp/localhost/9092' >/dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s


  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    # cpus: "0.05"
    # restart: unless-stopped
    mem_limit: "192m"
    mem_reservation: "128m"
    oom_score_adj: 500
    ports: 
      - "8080:8080"
    environment:
      # --- Kafka-UI (내부 브로커) ---
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_READONLY=false
    depends_on:
      kafka:
        condition: service_healthy
    networks: [logetlm-net]


  spark-master:
    image: spark:4.0.1-python3
    container_name: spark-master
    # # cpus: "0.05"
    # restart: unless-stopped
    mem_limit: "256m"
    mem_reservation: "128m"
    oom_score_adj: 0
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.master.Master"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "7077"
      - "--webui-port"
      - "8081"
    ports:
      - 7077:7077
      - 8081:8081
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  spark-driver:
    build:
      context: .
      dockerfile: spark_job/Dockerfile
    container_name: spark-driver
    # cpus: "1.0"
    restart: unless-stopped
    user: "1000:185"
    mem_limit: "2g"
    mem_reservation: "1500m"
    oom_score_adj: -100
    ports: 
      - "4040:4040"   # Spark UI (stream)
    environment:
      # --- Spark/Kafka connection (필수) ---
      - SPARK_MASTER_URL=spark://spark-master:7077
      - KAFKA_BOOTSTRAP=kafka:9092
      # --- Spark Streaming ingest ---
      - SPARK_FACT_TOPICS=logs.auth,logs.order,logs.payment,logs.error
      - SPARK_STARTING_OFFSETS=latest
      - SPARK_RESET_CHECKPOINT_ON_START=true
      - "SPARK_FACT_TRIGGER_INTERVAL=${SPARK_FACT_TRIGGER_INTERVAL:-4 seconds}"
      - SPARK_STORE_RAW_JSON=false
      - SPARK_STREAM_DRIVER_MEMORY=1g
      - SPARK_STREAM_EXECUTOR_MEMORY=2g
      - "SPARK_STREAM_SHUFFLE_PARTITIONS=${SPARK_STREAM_SHUFFLE_PARTITIONS:-8}"
      - "SPARK_ENV_PROFILE=${SPARK_ENV_PROFILE:-}"
      # --- maxOffsets 자동 계산 (target EPS 기반) ---
      - "SPARK_MAX_OFFSETS_PER_TRIGGER=${SPARK_MAX_OFFSETS_PER_TRIGGER:-}"    # 비어있으면 자동 계산
      - "SPARK_MAX_OFFSETS_SAFETY=${SPARK_MAX_OFFSETS_SAFETY:-1.1}"
      - "SPARK_MAX_OFFSETS_CAP=${SPARK_MAX_OFFSETS_CAP:-30000}"
      - "SPARK_KAFKA_MIN_PARTITIONS_MULTIPLIER=${SPARK_KAFKA_MIN_PARTITIONS_MULTIPLIER:-1}"
      # --- DLQ/에러 스트림 (선택) ---
      - SPARK_DLQ_TOPIC=logs.dlq
      - SPARK_ENABLE_DLQ_STREAM=false
      - SPARK_DLQ_TRIGGER_INTERVAL=30 seconds
      - SPARK_DLQ_KAFKA_TRIGGER_INTERVAL=60 seconds
      - SPARK_DLQ_KAFKA_LOG_EMPTY=false
      # --- Batch/metrics logging ---
      - SPARK_BATCH_TIMING_LOG_PATH=/data/log-etlm/spark-events/batch_timing.log
      # --- ClickHouse sink tuning ---
      - SPARK_CLICKHOUSE_URL=jdbc:clickhouse://clickhouse:8123/analytics?compress=0&decompress=1&jdbcCompliant=false&socket_timeout=600000&connect_timeout=10000
      - SPARK_CLICKHOUSE_USER=log_user
      - SPARK_CLICKHOUSE_PASSWORD=log_pwd
      - "SPARK_CLICKHOUSE_JDBC_BATCHSIZE=${SPARK_CLICKHOUSE_JDBC_BATCHSIZE:-10000}"
      - "SPARK_CLICKHOUSE_WRITE_PARTITIONS=${SPARK_CLICKHOUSE_WRITE_PARTITIONS:-3}"
      - "SPARK_SKIP_EMPTY_BATCH=${SPARK_SKIP_EMPTY_BATCH:-false}"
      - "SPARK_CLICKHOUSE_ALLOW_REPARTITION=${SPARK_CLICKHOUSE_ALLOW_REPARTITION:-false}"    # 업스케일은 repartition 필요
      - SPARK_FACT_DEDUP_KEYS=event_id
      - SPARK_CLICKHOUSE_RETRY_MAX=0
      - SPARK_CLICKHOUSE_RETRY_BACKOFF_SEC=1
      - SPARK_CLICKHOUSE_FAIL_ON_ERROR=true
    volumes:
      - ./common:/app/common:ro
      - ./spark_job:/app/spark_job:ro
      - ./config/env:/app/config/env:ro
      - ./log_simulator/config:/app/log_simulator/config:ro
      - /data/log-etlm/spark_checkpoints:/data/log-etlm/spark_checkpoints
      - /data/log-etlm/spark-events:/data/log-etlm/spark-events
    depends_on:
      kafka:
        condition: service_healthy
      spark-master:
        condition: service_started
      spark-worker-1:
        condition: service_started
      spark-worker-2:
        condition: service_started
      clickhouse:
        condition: service_healthy
    networks: [logetlm-net]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:4040/api/v1/applications >/dev/null || exit 1"]
      interval: 45s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }
    dns:
      - 127.0.0.11


  spark-worker-1:
    image: spark:4.0.1-python3
    container_name: spark-worker-1
    # cpus: "1.8"
    # restart: unless-stopped
    user: "185:185"
    mem_limit: "3500m"
    mem_reservation: "2500m"
    oom_score_adj: -50
    depends_on:
      - spark-master
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-master:7077"
      - "--cores"
      - "3"
      - "--memory"
      - "3g"
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  spark-worker-2:
    image: spark:4.0.1-python3
    container_name: spark-worker-2
    # cpus: "1.8"
    # restart: unless-stopped
    user: "185:185"
    mem_limit: "3500m"
    mem_reservation: "2500m"
    oom_score_adj: -50
    depends_on:
      - spark-master
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-master:7077"
      - "--cores"
      - "2"
      - "--memory"
      - "3g"
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  spark-batch-master:
    image: spark:4.0.1-python3
    container_name: spark-batch-master
    # # cpus: "0.05"
    # restart: unless-stopped
    mem_limit: "256m"
    mem_reservation: "128m"
    oom_score_adj: 0
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.master.Master"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "7078"
      - "--webui-port"
      - "8082"
    ports:
      - 7078:7078
      - 8082:8082
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  spark-batch-worker-1:
    image: spark:4.0.1-python3
    container_name: spark-batch-worker-1
    # cpus: "1.0"
    # restart: unless-stopped
    user: "185:185"
    mem_limit: "2g"
    mem_reservation: "1g"
    oom_score_adj: -50
    depends_on:
      - spark-batch-master
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-batch-master:7078"
      - "--cores"
      - "2"
      - "--memory"
      - "2g"
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  spark-batch:
    build:
      context: .
      dockerfile: spark_job/Dockerfile
    container_name: spark-batch
    user: "1000:185"
    mem_limit: "2g"
    mem_reservation: "1g"
    oom_score_adj: 200
    command: ["python", "-m", "spark_job.dimension.jobs.batch_job"]
    environment:
      # --- Dimension batch ---
      - SPARK_CLICKHOUSE_URL=jdbc:clickhouse://clickhouse:8123/analytics?compress=0&decompress=0&jdbcCompliant=false&socket_timeout=600000&connect_timeout=10000
      - SPARK_CLICKHOUSE_USER=log_user
      - SPARK_CLICKHOUSE_PASSWORD=log_pwd
      - SPARK_CLICKHOUSE_JDBC_FETCHSIZE=10000
      # --- Batch options ---
      - SPARK_BATCH_MASTER=spark://spark-batch-master:7078
      - SPARK_BATCH_DRIVER_MEMORY=2g
      - SPARK_BATCH_EXECUTOR_MEMORY=2g
      - SPARK_BATCH_SHUFFLE_PARTITIONS=64
      - DIM_BATCH_LOOKBACK_DAYS=1
      - DIM_SERVICE_MAP_PATH=
    volumes:
      - ./common:/app/common:ro
      - ./spark_job:/app/spark_job:ro
    depends_on:
      - clickhouse
      - spark-batch-master
      - spark-batch-worker-1
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  clickhouse:
    image: clickhouse/clickhouse-server:25.8.1.5101
    container_name: clickhouse
    # cpus: "0.8"
    # restart: unless-stopped
    mem_limit: "8g"
    mem_reservation: "6g"
    oom_score_adj: -200
    ports:
      - "127.0.0.1:8123:8123"
      - "127.0.0.1:9000:9000"
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    cap_add:
      - IPC_LOCK
      - SYS_NICE
    environment:
      # --- ClickHouse auth / access ---
      - CLICKHOUSE_USER=log_user
      - CLICKHOUSE_PASSWORD=log_pwd
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - /data/log-etlm/clickhouse:/var/lib/clickhouse
      - /data/log-etlm/clickhouse-logs:/var/log/clickhouse-server
      - ./infra/clickhouse/config.d:/etc/clickhouse-server/config.d:ro
      - ./infra/clickhouse/users.d:/etc/clickhouse-server/users.d
      - ./infra/clickhouse/sql/00_database.sql:/docker-entrypoint-initdb.d/00_database.sql:ro
      - ./infra/clickhouse/sql/10_fact.sql:/docker-entrypoint-initdb.d/10_fact.sql:ro
      - ./infra/clickhouse/sql/20_aggregates.sql:/docker-entrypoint-initdb.d/20_aggregates.sql:ro
      - ./infra/clickhouse/sql/21_materialized_views.sql:/docker-entrypoint-initdb.d/21_materialized_views.sql:ro
      - ./infra/clickhouse/sql/90_grants.sql:/docker-entrypoint-initdb.d/90_grants.sql:ro
    networks: [logetlm-net]
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --host localhost --query 'SELECT 1' >/dev/null"]
      interval: 45s
      timeout: 5s
      retries: 5
      start_period: 45s
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }

 
  ch-ui:
    image: ghcr.io/caioricciuti/ch-ui:latest    
    container_name: ch-ui
    # cpus: "0.05"
    # restart: always
    mem_limit: "192m"
    mem_reservation: "128m"
    oom_score_adj: 500
    ports:
      - "5521:5521"
    environment:
      # --- CH-UI connection ---
      VITE_CLICKHOUSE_URL: "http://localhost:8123"
      VITE_CLICKHOUSE_USER: "log_user"
      VITE_CLICKHOUSE_PASS: "log_pwd"
      # Optional: Advanced Features
      VITE_CLICKHOUSE_USE_ADVANCED: "false"
      VITE_CLICKHOUSE_CUSTOM_PATH: ""
      VITE_CLICKHOUSE_REQUEST_TIMEOUT: "30000"
      # Optional: Reverse Proxy Support
      VITE_BASE_PATH: "/"
    depends_on:
      - clickhouse
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


  grafana:
    image: grafana/grafana:10.4.2
    container_name: grafana
    # cpus: "0.05"
    # restart: unless-stopped
    mem_limit: "384m"
    mem_reservation: "256m"
    oom_score_adj: 200
    ports: 
      - "3000:3000"
    environment:
      # --- Grafana auth / security ---
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      # --- Plugins (optional) ---
      # - GF_INSTALL_PLUGINS=grafana-clickhouse-datasource
    volumes:
      - ./infra/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./infra/grafana/dashboards:/etc/grafana/dashboards:ro
      # NOTE: Grafana sqlite/db 및 캐시 파일도 /data로 분리
      - /data/log-etlm/grafana:/var/lib/grafana
    depends_on:
      clickhouse:
        condition: service_started
    networks: [logetlm-net]
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "5" }


networks:
  logetlm-net:
    driver: bridge
